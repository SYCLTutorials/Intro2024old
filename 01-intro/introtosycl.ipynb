{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d03299-b623-4a16-bd3b-0466edaa2b7e",
   "metadata": {},
   "source": [
    "# Introduction to SYCL Programming for GPUs\n",
    "\n",
    "In the rapidly evolving world of computing, the ability to harness the\n",
    "power of heterogeneous systems—where CPUs coexist with GPUs and other\n",
    "accelerators—has become increasingly vital. **SYCL** stands as a\n",
    "cutting-edge, single-source programming model designed to bridge this\n",
    "gap. Developed to be used with modern C++, SYCL abstracts the\n",
    "complexities associated with direct accelerator programming, making it\n",
    "accessible to both novice and experienced developers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf14782-a383-4c36-837f-4b7e75a64470",
   "metadata": {},
   "source": [
    "### What is SYCL?\n",
    "\n",
    "SYCL is an open standard developed by the Khronos Group, the same group\n",
    "responsible for OpenGL. It allows developers to write code for\n",
    "heterogeneous systems using completely standard C++. This means that the\n",
    "same code can target CPUs, GPUs, DSPs, FPGAs, and other types of\n",
    "accelerators without modification. SYCL builds upon the foundation laid\n",
    "by OpenCL, offering a higher level of abstraction and deeper integration\n",
    "with C++.\n",
    "\n",
    "<img width=\"800\" src=https://www.khronos.org/assets/uploads/apis/2022-sycl-diagram.jpg>\n",
    "Image Source. https://www.khronos.org/sycl/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7fa39-433f-4693-9058-28c6b66553bd",
   "metadata": {},
   "source": [
    "### Advantages of SYCL\n",
    "\n",
    "One of the primary advantages of SYCL is its ability to integrate\n",
    "seamlessly with C++17 and upcoming versions, enabling features like\n",
    "lambda functions, auto-typing, and templating. This integration not only\n",
    "improves the programmability and readability of the code but also\n",
    "leverages the type safety and performance optimizations provided by\n",
    "modern C++. Here are a few key benefits: - **Single-Source\n",
    "Development**: Unlike traditional approaches that might require\n",
    "maintaining separate code bases for different architectures, SYCL\n",
    "unifies the code into a single source. This simplifies development and\n",
    "reduces maintenance burdens. - **Cross-Platform Portability**: SYCL code\n",
    "can be executed on any device that has a compatible SYCL runtime,\n",
    "providing true cross-platform capabilities. - **Performance**: With\n",
    "SYCL, developers do not have to sacrifice performance for portability.\n",
    "It allows fine control over parallel execution and memory management,\n",
    "which are critical for achieving optimal performance on GPUs.\n",
    "\n",
    "As GPUs continue to play a crucial role in fields ranging from\n",
    "scientific computing to machine learning, mastering SYCL can provide\n",
    "developers with the tools needed to fully exploit the capabilities of\n",
    "these powerful devices. The following sections will guide you through\n",
    "setting up your development environment, understanding the core concepts\n",
    "of SYCL, and walking you through practical examples to kickstart your\n",
    "journey in high-performance computing with SYCL.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "This introduction sets the stage for learning SYCL by highlighting its\n",
    "relevance, advantages, and integration with modern C++. It aims to build\n",
    "a strong foundation for the subsequent sections that delve deeper into\n",
    "SYCL programming.\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d670a-b89b-4b12-a352-483d93bdf457",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0417cc05-18bb-48c6-af6a-18e18fb69c08",
   "metadata": {},
   "source": [
    "# Enqueuing A Kernel\n",
    "\n",
    "In SYCL, all computations are submitted through a queue. This queue is\n",
    "associated with a device, and any computation assigned to the queue is\n",
    "executed on this device.\n",
    "\n",
    "SYCL offers two methods for managing data: 1. **Buffer/Accessor Model:**\n",
    "This model uses buffers to store data and accessors to read or write\n",
    "data, ensuring safe memory management and synchronization. 2. **Unified\n",
    "Shared Memory (USM) Model:** This model allows for direct data sharing\n",
    "between the host and device, simplifying memory management by\n",
    "eliminating the need for explicit buffers and accessors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc94a5c-f22c-4146-b4d2-ed45585ce325",
   "metadata": {},
   "source": [
    "# Command Groups\n",
    "\n",
    "A command group is a fundamental construct that encapsulates a set of\n",
    "operations meant to be executed on a device.\n",
    "\n",
    "<img width=\"455\" alt=\"\" src=\"./images/image1.png\" >\n",
    "<img src=https://raw.githubusercontent.com/oneapi-src/oneAPI-samples/495ff2bb29b50698e9c6d3b12f7d8cf476e73d02/DirectProgramming/C++SYCL/Jupyter/oneapi-essentials-training/01_oneAPI_Intro/Assets/oneapi1.png>\n",
    "\n",
    "-   Command groups are defined by calling the **submit** function on the\n",
    "    queue.\n",
    "-   The **submit** function takes a command group handler (`cgh`) which\n",
    "    facilitates the composition of the command group.\n",
    "-   Inside the **submit** function, a handler is created and passed to\n",
    "    the `cgh`.\n",
    "-   This handler is then used by the `cgh` to assemble the command\n",
    "    group.\n",
    "\n",
    "``` cpp\n",
    "gpuQueue.submit([&](sycl::handler &cgh) {\n",
    "  /* Command group function */\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a544695-74f5-4807-81da-6db8aa42e0d3",
   "metadata": {},
   "source": [
    "# Scheduling\n",
    "\n",
    "A schedulre is a component responsible for managing the order and\n",
    "execution of tasks on computational resources.\n",
    "\n",
    "![Scheduling Overview](attachment:./images/image3.png)\n",
    "\n",
    "-   When the **submit** function is called, it creates a command group\n",
    "    handler (`cgh`) and submits it to the scheduler.\n",
    "-   The scheduler is responsible for executing the commands on the\n",
    "    designated target device.\n",
    "\n",
    "#### Enqueuing SYCL Kernel Function example\n",
    "\n",
    "``` cpp\n",
    "class hello_world;\n",
    "\n",
    "// Check for available GPU devices\n",
    "auto gpu_selector = sycl::gpu_selector{};\n",
    "try {\n",
    "  // Create a queue using the GPU selector\n",
    "  auto gpuQueue = sycl::queue{gpu_selector};\n",
    "\n",
    "  // Submit a command group to the queue\n",
    "  gpuQueue.submit([&](sycl::handler &cgh) {\n",
    "    // Create a stream for output within kernel\n",
    "    auto os = sycl::stream{128, 128, cgh};\n",
    "\n",
    "    // Execute a single task\n",
    "    cgh.single_task<hello_world>([=]() {\n",
    "      os << \"Hello World!\\n\";\n",
    "    });\n",
    "  }).wait(); // Wait for completion\n",
    "\n",
    "  std::cout << \"Successfully executed on GPU.\\n\";\n",
    "} catch (sycl::exception const& e) {\n",
    "  // Fallback if no GPU is found\n",
    "  std::cerr << \"No GPU device found. Error: \" << e.what() << '\\n';\n",
    "  std::cerr << \"Trying to fallback to CPU.\\n\";\n",
    "  auto cpuQueue = sycl::queue{sycl::cpu_selector{}};\n",
    "  cpuQueue.submit([&](sycl::handler &cgh) {\n",
    "    auto os = sycl::stream{128, 128, cgh};\n",
    "    cgh.single_task<hello_world>([=]() {\n",
    "      os << \"Hello World from CPU!\\n\";\n",
    "    });\n",
    "  }).wait();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5ca8d-07f7-4867-a9d9-aa814e7f86af",
   "metadata": {},
   "source": [
    "# Buffers & Accessors\n",
    "\n",
    "Buffers and accessors are used in SYCL for managing and accessing data\n",
    "across different computing devices, including CPUs, GPUs, and other\n",
    "accelerators:\n",
    "\n",
    "![Diagram illustrating the relationship between buffers, accessors, and\n",
    "devices](attachment:./images/image2.png)\n",
    "\n",
    "-   **Buffers**: Buffers are used to manage data across the host and\n",
    "    various devices. A buffer abstractly represents a block of data and\n",
    "    handles the storage, synchronization, and consistency of this data\n",
    "    across different memory environments. When a buffer object is\n",
    "    constructed, it does not immediately allocate or copy data to the\n",
    "    device memory. This allocation or transfer only occurs when the\n",
    "    runtime determines that a device needs to access the data,\n",
    "    optimizing memory usage and data transfer.\n",
    "\n",
    "-   **Accessors**: Accessors are used to request access to data that is\n",
    "    stored in buffers. They specify how and when the data in a buffer\n",
    "    should be accessed by a kernel function, either on the host or a\n",
    "    specific device. Accessors help in defining the required access\n",
    "    pattern (read, write, or read/write) and are crucial for ensuring\n",
    "    data consistency and coherency between the host and devices.\n",
    "\n",
    "``` cpp\n",
    "class vector_dot_product;\n",
    "\n",
    "const int N = 1024; // Length of the vectors\n",
    "std::vector<int> vectorA(N, 1); // Vector A filled with 1s\n",
    "std::vector<int> vectorB(N, 2); // Vector B filled with 2s\n",
    "int result = 0; // Result of dot product initialized to zero\n",
    "\n",
    "auto gpu_selector = sycl::gpu_selector{};\n",
    "\n",
    "auto bufA = sycl::buffer{vectorA.data(), sycl::range{N}};\n",
    "auto bufB = sycl::buffer{vectorB.data(), sycl::range{N}};\n",
    "auto bufResult = sycl::buffer{&result, sycl::range{1}};\n",
    "\n",
    "gpuQueue.submit([&](sycl::handler& cgh) {\n",
    "    auto accA = bufA.get_access<sycl::access::mode::read>(cgh);\n",
    "    auto accB = bufB.get_access<sycl::access::mode::read>(cgh);\n",
    "    auto accResult = bufResult.get_access<sycl::access::mode::read_write>(cgh);\n",
    "\n",
    "    cgh.parallel_for<vector_dot_product>(sycl::range{N}, [=](sycl::id<1> idx) {\n",
    "        int i = idx[0];\n",
    "        accResult[0] += accA[i] * accB[i];\n",
    "    });\n",
    "}).wait();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4613df-1477-4623-9313-4f33bc01720a",
   "metadata": {},
   "source": [
    "# How to compile SYCL code\n",
    "\n",
    "> If you’re gonna build a time machine into a car, why not do it with\n",
    "> some style?\n",
    ">\n",
    "> — *Back to the Future*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c50da-036b-494b-aafb-5883e7a09bbe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af482c-0429-4d3a-bed2-e3d112fa4471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
